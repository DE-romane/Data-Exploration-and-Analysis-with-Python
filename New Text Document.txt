[Music], hi my name is mochan and for those of, you who are new to this channel this, channel is all about sharing my, Knowledge and Skills that I've acquired, over the years as a data analyst for, those of you who are not new to this, channel thank you so so much for, watching and subscribing I never even, thought that I could get over a thousand, subscribers and at the time of this, recording I have over 2 000 subscribers, on this channel so the fact that you're, engaging subscribing listening and, watching means so so much to me so I, just want to say a big thank you to you, all who have been watching and, subscribing thank you so so much I'm, gonna try my best to keep on delivering, great content going forwards, [Music], in today's video I'm gonna show you how, I explore data using python in a jupyter, notebook as a data analyst I'm not going, to type out the code from scratch but, what I will do is I'll go through the, more complex codes in more detail I'm, gonna break it down so you can easily, understand what's going on we're also, going to answer some questions within, this exercise and there's going to be, some questions that I will not answer in, this video so you can attempt it by, yourself at home, don't worry if you don't know the, solution because there's a link below to, the GitHub repository that will contain, the data file the exercise file and the, solution file, first things first let's import all of, the necessary libraries that we'll be, using so we'll use the numpy the pandas, the matplotlib Seaborn and alias's, libraries underneath that I'm using, percent matplotlib inline to make the, plots appear directly below the cell and, then after that I'm actually using this, for Loop to find the correct encoding, that I can use to read in my CSV file, now I'm using this because by default, pandas will use utf-8 encoding which in, this case will not work unfortunately so, let me just show you that it doesn't, actually work so if I just go pd.read, csvcrime.csv you see that I get an error, message so it doesn't work which is why, I need to find the correct encoding, essentially what's happening here is, just that I'm importing the aliases, Library which contains a dictionary of, the encoding names that we can use and, then within that I'm going to print out, the ones that I can actually use for, this file so I'm saying successful and, then print out the encoding name and, within here I'm only reading in the, first 10 rows to make my code run, quickly and efficiently so let me just, run that and then you see all of these, encodings that we can use to read in our, crime.csv file so next up I just chose, one of these encodings ISO 885911 and, I'm reading in my crime.csv CSV file, after that I'm using crime.head to, quickly check out the table the, beginning of the data frame you can see, all of the columns you can scroll, through and check out the values, underneath that I'm using crime.shape to, check out the shape of the data frame so, it returns two values the first one is, the number of rows so we can see that we, have 319 073 rows and 17 columns within, this data frame and then I'm using, crime.duplicated dot sum to find the, number of the duplicated rows so let me, just break this code down so let me just, show you what crime dot duplicated would, give you first so this will give you a, false or true depending on whether or, not the row is a duplicated row and then, by summing them you're just summing the, True Values and this is equal to 23., next up we're gonna drop the duplicates, and I'm using in place is equal to true, because I want to make my changes, permanent so after running the cell I'm, using prime.shape to check the shape of, the data frame again and you see here, now that we're only left with 319 050, rows so we have successfully removed 23, rows now let's dig a little bit deeper, and really floor the data set again you, can use crime.head to print out the, beginning of the data frame and then you, can use the tail function to check the, end of the data frame or you could just, simply use crime and then you can see, the beginning and the end of the data, frame pandas by default will give you 10, rows of data but you can change this by, specifying the options so you could say, for example change this to be equal to 6, and then if I run crime again now I'm, only left with six rows of data let me, just change this back to the default so, it's equal to 10 and then let me print, crime again and you see we're left with, 10 rows of data again next up I'm using, the dot info function to get some, summary information about the data frame, so you get the column back you get the, non-null counts and then the data type, of the column so if we just look at, incident number for example we can see, that it's got no missing values so we, have 319 050 non-null values and then, it's of object data type we can look at, shooting for example we can see that we, only have 1019 not null values which to, me suggest that it's either yes or a, blank and then we can look at occurred, on date for example which also has no, missing values and is of object data, type now but in the next line we are, going to convert this column here into a, date time column so we're doing this, because we want to be able to easily, extract date time information from the, column and we can only do so if it's a, date time column so I'm using the two, date time function here to convert my, column and then I'm using crime.info, again to see if it has worked and you, see here occurred on date now as of date, time and this is what we wanted because, now we can extract any kind of date time, information so here I'm extracting the, year next stop I'm going to extract the, month next up I'm gonna extract the week, and then the hour and then the minute so, on and so forth so you see how useful, this is to extract any kind of daytime, information, next up I'm using the describe method to, get some information on the numeric, columns and then underneath that I'm, using the option include object to get, summary information on the non-numeric, columns so let's quickly have a look at, the output of this and how we could, interpret this so say for example if I, look at the incident number column here, we have 319 050 values but we only have, 282 and 517 unique values which suggests, uh to me that we have duplicate incident, numbers which is okay because there, might be multiple types of crimes, committed or multiple types of offenses, committed within a single incident we, can also look at the district column, here for example we can see that we have, 12 unique districts and the most, frequently occurring one is V2 and it, occurs 49 and 940 times or we could look, at reporting area for example and we, have 879 distinct unique reporting areas, we could also look at shooting like we, said before we have 1019 non-known, values we have only one unique value, which is just a yes flag so it's either, yes or it's a blank next up we can look, at day of week for example we have seven, unique values which makes sense because, we have Days running from Monday to, Sunday and then Friday is the most, frequently occurring day moving on we, can print the columns within our data, frame just by using the dot columns, method so you have all of the columns, returned and then next up I'm actually, gonna check for columns with missing, values here so once you use numpy.com, you can sum up the values within the, column and then you make the value not, equal to zero because you want the, values to be missing and then you slice, your crime.columns according to this, criteria here which returns District, shooting UCR part Street latitude and, longitude as the missing values so to, break this code down just a little bit, let me start with crying, first and this will just return you a, data frame we choose and falses, depending on whether or not the value is, missing so now we can use numpy.com so, np.com and I'm going to sum these values, and then now you get the missing values, in each of the columns you can make this, not equal to zero because you want, columns with missing values so you want, to retain the true ones and then you use, crime dot columns and then you make sure, you slice this list according to this, criteria and this is how you end up with, these column names here now of course, you can check for the columns with no, missing values so all you would have to, do is make this equal to zero and then, there you go these are the columns with, no missing values next up I'm using a, simple for Loop to check for the number, of unique values in each of the columns, and then I am going to print out the, column name and then has how many and, then unique values and that's it that's, the for Loop that I'm running here and, done it's just an easy way to check for, Unique values so like I said before day, of week has seven unique values hour, here has 24 unique values again it makes, sense because we have 24 hours month has, 12 unique values and then, we also checked reporting area 879, unique values and then we also have 12, unique districts moving on to answering, some questions some exploratory, questions using this data so question, number one is what are the most common, crimes in terms of offense groups so I'm, using a really helpful function here, value counts and value accounts will, just give you the counts of each of, these values so we can see that we have, 37, 132 counts of motor vehicle accident, responses uh 25 935 counts of larceny, and then medical assistance investigate, person so on and so forth next up with, this piece of code here offense group, valves I'm just getting the top 10, values out of, offensecodegroup.value counts and I'll, show you how I got that so let me just, print value counts again so all I'm, doing here is I'm gonna slice this list, to only include the first 10 use and, there you go this is it next up I'm, gonna display the offense group valves, as a percentage of the total crimes and, I'm using crime.shape and I'm picking, the first element of that because I want, to divide by the total of row numbers, that we have within the data set so just, to refresh our memory Prime dot shape, gives me 319 050 rows and 17 columns and, I want to get the rows out of this so, I'm just picking the first element which, is 319 050. so I'm gonna print this out, and I'm creating a bar chart after that, with the same values so let me just run, this, and there you go we have all of these, values as a percentage of total crimes, and then we have the same in this bar, chart as well okay so moving on what are, the least common offense groups so, almost the same piece of code but at the, end I'm gonna sort the values ascending, and then I'm picking the first 10 values, so there you go you can see that, burglary human trafficking which is, quite bad very bad actually biological, threat investigate person and the human, trafficking so on and so forth these, were the least common offense groups, moving on it's the first question for, you to answer at home make sure you try, and attempt it I do have the solution in, the GitHub repository as well so have a, go at it and then check the solution so, question number one what are the most, common offense descriptions and I, provided a little hint here you can use, the value counts method here, and then question number two for you you, can try and create a bar chart of the, top 10 offense descriptions as a, percentage of the total crime so very, similar to what we just uh saw right, here in this field so we were looking at, top 10 offense groups so now you're, going to be looking at top 10 offense, descriptions make sure you have a go at, it okay so let's move on to our next, question within this video which is in, which year were the most crimes, committed here it's a little bit, different now because I'm grouping by, the year first then I'm counting the, incident numbers and then I'm plotting, the whole thing as a bar chart and I'm, using plt.title to give my bar chart a, title which is number of crimes and, there you go so the group by method is, super helpful when you just want to, Aggregate and let me just show you how, it works so I'm gonna Group by the year, and then you see here what you're, creating is actually just a data frame, Group by object so you need to choose, some kind of aggregation method you, could use some foreign example and then, it would return you a data frame or you, could use mean for example and it would, also return something but in this case, we just want to count the incident, numbers so we're using the count method, and then out of these columns all I want, to return is the incident number which, is why I'm slicing and I'm only choosing, the incident number column and there you, go this is the little table that we have, and this is what is visualize blue in, the form of a bar chart and moving on to, question number three for you are there, more crimes committed on specific days, make sure to use a bar chart to try and, answer this question it'll be quite, similar to the group by year here so, make sure you have a go at it at home, and then our next question is are there, more crimes during specific hours so, this time we're going to group by the, hour and then we're doing the exact same, thing as before counting and then, choosing the incident number column and, we're going to plot this as a board, chart and when you look at the board, chart it kind of makes sense when p, people are not awake I guess it's maybe, too early for a crime between 3 AM and 6, a.m and most crimes happen late in the, evening so after 4 pm 5 p.m 6 p.m quite, a lot of crime at midnight as well if, you can see here next up we're gonna, answer this question on what days and, during which hours are the most crimes, committed so this time the difference is, we're going to group by the hour and the, day of the week here then we're gonna, count and then we're picking the, incident number column and then we, actually need to unstack our data frame, so we can actually use a heat map so let, me just run this code here and then let, me just break it down so crime.group by, and then count incident number we all, know what this looks like so it'll look, like this but this is not a heat map and, that's why we're using the onstack, function here and the moment you unstack, it you see that the days turn into the, columns and then the hour itself will be, the index but now we have fry day Monday, Saturday Sunday it's random the days in, which order they appear so next up I'm, using this code here to rearrange the, columns so they actually run from Monday, to Sunday, so once I've done that I'm using Seaborn, and Seabourn has a built-in function, called heat map all you have to pass in, is a data frame and then you can choose, whatever color map you want so I went, for the sns.qp elix palette and then if, I run this I'm going to get a nice heat, map and you can see that most crimes, occur on Monday and Tuesday and Saturday, and Sunday between 5 and 6 if you just, look at this heat map quickly okay so, moving on to two more questions in which, months were the number of crimes the low, average and in which months on average, did the most crimes occur, so now what we're going to do is we're, going to use a table representation to, do this so if the value is less than the, average crime per month we're going to, highlight the value in blue so in order, to do this first we need to find the, average crime per month so I'm going to, use crime dot Group by year and then the, month and then I'm going to count and, then I'm picking the instant number, again and then I'm just choosing the, mean function because I want to return, the average so underneath that I'm going, to print this average crime number and, then I'm creating year and month data, frame using crime.group by again I'm, going to group by the month and then the, year count and then I'm picking the, incident number column and I'm going to, unstack this to be able to create a, table then I have this function, underneath essentially all this does is, that if my value is less than the, average crime then highlight the value, in blue so after running this you see, the table below here all of the values, that are under, 7976.25 are highlighted in blue so, 4188 yes less than the average 667, 7935. these are all values that are, under the average crime now underneath, that we're gonna use the apply function, to highlight the maximum in a column in, dark green so this function underneath, will highlight the maximum value in dark, green in a column so once I run this you, can see that the above chart changed as, well but this is our final chart here, these two charts are exactly the same so, now we have the below average values, highlighted in blue and then we have the, maximum value across the years so in, 2015 we have the maximum value of, 8411 highlighted in dark green and then, we also take the maximum values across, all of the columns here which gets us on, to our final question this might be a, little bit of a challenge but I'm sure, if you have a go at it you can easily do, this at home but don't worry if you, can't because like I said there's also, the solution uploaded in the GitHub, repository so question number four in, which districts were the most crimes, committed on a yearly basis and I left a, little hint here essentially just try, and use everything you've learned in, this video to answer the question feel, free to use functions tables other, visuals there's numerous solutions to, this so if you come up with something, way better and something that looks way, nicer than my solution make sure you, upload it somewhere leave a link in the, comments below I'd be so happy and so, Keen to see you know what you've come up, with let me know I really hope that, you'll have a go at the exercises by, yourself at home as learning by doing is, probably the best way to learn if you, found this video useful entertaining or, you like this video make sure you check, out some of my other videos right here, again thank you so so much for watching, engaging and subscribing it really means, a lot to me and like I said I will, absolutely do my best to keep on, delivering great content See in the next, one, foreign,